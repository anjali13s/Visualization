{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = requests.get('https://www.tripadvisor.com/Hotels-g298570-Kuala_Lumpur_Wilayah_Persekutuan-Hotels.html')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(kl.text)\n",
    "\n",
    "kl_links = []\n",
    "for link in soup.find_all('a'):\n",
    "    class1 = link.get('class')\n",
    "\n",
    "    if class1!= None:\n",
    "        if class1[0]=='review_count':\n",
    "            kl_links.append(link.get('href'))\n",
    "            if (len(kl_links)>19):\n",
    "                break\n",
    "\n",
    "# print(kl_links)  \n",
    "# print(len(kl_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = requests.get('https://www.tripadvisor.com/Hotels-g293916-Bangkok-Hotels.html')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(b.text)\n",
    "\n",
    "b_links = []\n",
    "for link in soup.find_all('a'):\n",
    "    class1 = link.get('class')\n",
    "\n",
    "    if class1!= None:\n",
    "        if class1[0]=='review_count':\n",
    "            b_links.append(link.get('href'))\n",
    "            if (len(b_links)>19):\n",
    "                break\n",
    "\n",
    "# print(b_links)  \n",
    "# print(len(b_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-54c2a2b10202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mstart_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mend_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "base_url_s = 'https://www.tripadvisor.com/Hotels-g294265-Singapore-Hotels.html' \n",
    "s = requests.get(base_url_s)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(s.text)\n",
    "\n",
    "singapore_links = [] #contains the path to each of the 20 hotels\n",
    "for link in soup.find_all('a'):\n",
    "    class1 = link.get('class')\n",
    "\n",
    "    if class1!= None:\n",
    "        if class1[0]=='review_count':\n",
    "            singapore_links.append(link.get('href'))\n",
    "            if (len(singapore_links)>19):\n",
    "                break\n",
    "\n",
    "\n",
    "#print(singapore_links)  \n",
    "#print(len(singapore_links))\n",
    "\n",
    "hotelList = []\n",
    "\n",
    "for n in range (20):\n",
    "    hotel = dict()\n",
    "    \n",
    "    new = 'https://www.tripadvisor.com' + singapore_links[n]\n",
    "    a = requests.get(new)\n",
    "    soup_a = BeautifulSoup(a.text)\n",
    "    for a_span in soup_a.find('h1'):\n",
    "        hotel_name = a_span\n",
    "        hotel['Name'] = hotel_name\n",
    "    \n",
    "    for div in soup_a.find_all('div'):\n",
    "        ID = div.get('id')\n",
    "\n",
    "        if ID!= None:\n",
    "            if ID =='ABOUT_TAB':\n",
    "                for span in div.find_all('span'):\n",
    "                    if(span.text!= ''):\n",
    "                        overall_rating = span.text\n",
    "                        if (len(span.text)>1):\n",
    "                               break \n",
    "                                \n",
    "                    \n",
    "    hotel['Overall Rating'] = overall_rating            \n",
    "                                  \n",
    "    count=0\n",
    "    \n",
    "    \n",
    "    for j in range(len(new)):\n",
    "        if new[j]=='-':\n",
    "            count+=1\n",
    "        if count== 4:\n",
    "            start_url = new[:j+1]\n",
    "            end_url = new[j:]\n",
    "            break\n",
    "            \n",
    "#     for k in range(5):\n",
    "#         url = start_url+'or{}'.format(k*5)+end_url\n",
    "     \n",
    "#         a = requests.get(url)\n",
    "#         soup_a = BeautifulSoup(a.text)\n",
    "\n",
    "#         for a_span in soup_a.find_all('q'):\n",
    "# #             print(a_span)\n",
    "# #             print(a_span.text)\n",
    "#             reviews_h.append(a_span.text)\n",
    "#             hotel['Reviews'] = reviews_h    \n",
    "                  \n",
    "\n",
    "\n",
    "#         for div in soup_a.find_all('div'):\n",
    "#             target = div.get('data-test-target')\n",
    "\n",
    "#             if target!= None:\n",
    "#                 if target=='review-rating':\n",
    "#                     for span in div.find_all('span'):\n",
    "#                         class1 = span.get('class')\n",
    "#                         temp = class1[1]\n",
    "#                         individual_rating = int(temp[-2:])/10\n",
    "#                         ratings.append(individual_rating)\n",
    "#             hotel['Individual Ratings'] = ratings\n",
    "        \n",
    "#     print('AAAAAAAAAAAA')\n",
    "#     print(len(reviews_h))\n",
    "#     print(\"AAAAAAAAAAAA\")\n",
    "\n",
    "    ##### reviews and individual ratings    \n",
    "    \n",
    "    reviewURLs = []\n",
    "    reviews_h = []\n",
    "    ratings = []\n",
    "    \n",
    "    for k in range(20):\n",
    "        url = start_url+'or{}'.format(k*5)+end_url\n",
    "\n",
    "        a = requests.get(url)\n",
    "        soup_a = BeautifulSoup(a.text)\n",
    "        for div in soup_a.find_all('div'):\n",
    "            target = div.get('data-test-target')\n",
    "\n",
    "            if target!= None:\n",
    "                if target=='review-title':\n",
    "                    for link in soup_a.find_all('a'):\n",
    "                        reviewURLs.append(link.get('href'))\n",
    "                    \n",
    "    \n",
    "                \n",
    "\n",
    "    \n",
    "            \n",
    "    hotelList.append(hotel)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "# print(len(hotel['Individual Ratings']))    \n",
    "# print(len(hotel['Reviews']))\n",
    "# df = pd.DataFrame(hotel)\n",
    "# df[\"Name\"]=hotel_name\n",
    "# df.to_csv('hotel.csv')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "99\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "99\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "95\n",
      "95\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "95\n",
      "95\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for n in range (20):\n",
    "    \n",
    "    hotel = dict()\n",
    "    \n",
    "    new = 'https://www.tripadvisor.com' + singapore_links[n]\n",
    "    a = requests.get(new)\n",
    "    soup_a = BeautifulSoup(a.text)\n",
    "    \n",
    "    # mining hotel name\n",
    "    for a_span in soup_a.find('h1'):\n",
    "        hotel_name = a_span\n",
    "        \n",
    "    # mining hotel's overall rating \n",
    "    for div in soup_a.find_all('div'):\n",
    "        ID = div.get('id')\n",
    "        if ID!= None:\n",
    "            if ID =='ABOUT_TAB':\n",
    "                for span in div.find_all('span'):\n",
    "                    if(span.text != ''):\n",
    "                        overall_rating = span.text\n",
    "                        if (len(span.text)>1):\n",
    "                               break         \n",
    "    \n",
    "    count = 0\n",
    "    reviews_h = []\n",
    "    ratings = []\n",
    "    \n",
    "    for j in range(len(new)):\n",
    "        if new[j] == '-':\n",
    "            count += 1\n",
    "        if count == 4:\n",
    "            start_url = new[:j+1]\n",
    "            end_url = new[j:]\n",
    "            break\n",
    "\n",
    "    for k in range(20):\n",
    "        print(k)\n",
    "        url = start_url + 'or{}'.format(k*5) + end_url\n",
    "        c = requests.get(url)\n",
    "        soup_c = BeautifulSoup(c.text)\n",
    "        # mining user reviews and ratings\n",
    "        for div in soup_c.find_all('div'):\n",
    "            target = div.get('data-test-target')\n",
    "            if target != None:\n",
    "                if target =='review-title':\n",
    "                    link = div.find_next('a')\n",
    "                    userReviewLink = 'https://www.tripadvisor.com' + link.get('href')\n",
    "                    b = requests.get(userReviewLink)\n",
    "                    soup_b = BeautifulSoup(b.text)\n",
    "                    for each in soup_b.find_all('span'):\n",
    "                        target2 = each.get('class')\n",
    "                        if target2!= None and len(target2)>0:\n",
    "                            if target2[0] == 'fullText':\n",
    "                                reviews_h.append(each.text)\n",
    "                    for each in soup_b.find_all('div'):\n",
    "                        target2 = each.get('class')\n",
    "                        if target2!= None and len(target2)>2:\n",
    "                            if target2[2] == 'hero_review_block':\n",
    "                                for every in each.find_all('span'):\n",
    "                                    target3 = every.get('class')\n",
    "                                    if target3 != None and len(target3)>0:\n",
    "                                        if target3[0] == 'ui_bubble_rating':\n",
    "                                            string = target3[1]\n",
    "                                            ratings.append(int(string[-2:])/10)\n",
    "\n",
    "                           \n",
    "    hotel['Name'] = hotel_name                 \n",
    "    hotel['Overall Rating'] = overall_rating                                      \n",
    "    hotel['User Ratings'] = ratings\n",
    "    hotel['User Reviews'] = reviews_h\n",
    "    \n",
    "    print(len(ratings))\n",
    "    print(len(reviews_h))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindf = pd.DataFrame()\n",
    "\n",
    "for n in range (20):\n",
    "    \n",
    "    hotel = dict()\n",
    "    \n",
    "    new = 'https://www.tripadvisor.com' + singapore_links[n]\n",
    "    a = requests.get(new)\n",
    "    soup_a = BeautifulSoup(a.text)\n",
    "    \n",
    "    # mining hotel name\n",
    "    for a_span in soup_a.find('h1'):\n",
    "        hotel_name = a_span\n",
    "        \n",
    "    # mining hotel's overall rating \n",
    "    for div in soup_a.find_all('div'):\n",
    "        ID = div.get('id')\n",
    "        if ID!= None:\n",
    "            if ID =='ABOUT_TAB':\n",
    "                for span in div.find_all('span'):\n",
    "                    if(span.text != ''):\n",
    "                        overall_rating = span.text\n",
    "                        if (len(span.text)>1):\n",
    "                               break         \n",
    "    \n",
    "    count = 0\n",
    "    reviews_h = []\n",
    "    ratings = []\n",
    "    \n",
    "    for j in range(len(new)):\n",
    "        if new[j] == '-':\n",
    "            count += 1\n",
    "        if count == 4:\n",
    "            start_url = new[:j+1]\n",
    "            end_url = new[j:]\n",
    "            break\n",
    "\n",
    "    for k in range(20):\n",
    "        print(k)\n",
    "        url = start_url + 'or{}'.format(k*5) + end_url\n",
    "        c = requests.get(url)\n",
    "        soup_c = BeautifulSoup(c.text)\n",
    "        # mining user reviews and ratings\n",
    "        for div in soup_c.find_all('div'):\n",
    "            target = div.get('data-test-target')\n",
    "            if target != None:\n",
    "                if target =='review-title':\n",
    "                    link = div.find_next('a')\n",
    "                    userReviewLink = 'https://www.tripadvisor.com' + link.get('href')\n",
    "                    b = requests.get(userReviewLink)\n",
    "                    soup_b = BeautifulSoup(b.text)\n",
    "                    for each in soup_b.find_all('span'):\n",
    "                        target2 = each.get('class')\n",
    "                        if target2!= None and len(target2)>0:\n",
    "                            if target2[0] == 'fullText':\n",
    "                                reviews_h.append(each.text)\n",
    "                    for each in soup_b.find_all('div'):\n",
    "                        target2 = each.get('class')\n",
    "                        if target2!= None and len(target2)>2:\n",
    "                            if target2[2] == 'hero_review_block':\n",
    "                                for every in each.find_all('span'):\n",
    "                                    target3 = every.get('class')\n",
    "                                    if target3 != None and len(target3)>0:\n",
    "                                        if target3[0] == 'ui_bubble_rating':\n",
    "                                            string = target3[1]\n",
    "                                            ratings.append(int(string[-2:])/10)\n",
    "\n",
    "                           \n",
    "                                          \n",
    "    hotel['User Ratings'] = ratings\n",
    "    hotel['User Reviews'] = reviews_h\n",
    "    \n",
    "    df = pd.DataFrame(hotel)\n",
    "    df['Name'] = hotel_name\n",
    "    df['Overall Rating'] = overall_rating\n",
    "    maindf.append(df)\n",
    "    \n",
    "    \n",
    "maindf.to_csv('mining.csv')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
